---
title: "Prédiction des prix"
author: "Mohamed Maftah (mohamed.maftah@polymtl.ca) & Mehdi Miah (mehdi.miah@gmail.com)"
date: "`r format(Sys.time(), '%d-%m-%Y')`"
output:
  html_document:
    df_print: kable
    fig_caption: yes
    number_sections: yes
    toc: yes
---

**Descriptif** : sur le fichier des produits en 'Electronics', prédit le prix d'un produit

# Setup

```{r setup, message = FALSE, warning = FALSE}

# Suppression des variables
rm(list = ls())

# Chargement des librairies
library(data.table) #pour fread
library(knitr) #pour le notebook
library(ggplot2)
library(tm) #pour le text mining (Corpus et etc)
library(randomForest)
library(tidyr)
library(dplyr)

```

# Ouverture du fichier

```{r, message = FALSE}
# Eléments considérés comme NA
na_strings = c(NA, '', '.', ' ', '?')

# Dataset au complet
dataset = fread("./data/intermediate/dataset_electronics.csv", data.table = FALSE,
                sep = ";", encoding = "UTF-8", na.strings = na_strings,
                colClasses = c("integer", "character", "factor", "factor", "factor", "factor", 
                               "numeric", "integer", "character", "logical", "numeric"))
```

```{r}
# Fonction RMSE d'erreur
rmse = function(y_pred, y_true, na.rm = FALSE){
  if(length(y_pred) != length(y_true)){
    stop("Les deux vecteurs ne sont pas de même dimension !\n")
  }else{
    rmse = (mean((y_pred - y_true)**2, na.rm = na.rm)) ** (1/2)
    return(rmse)
  }
  
}
```


# Modèle de prédiction

Pour évaluer les performances d'un modèle "complexe", il convient tout d'abord d'avoir une estimation du pouvoir prédictif de modèles plus simples. A partir de l'analyse des données, il s'est avéré que l'ensemble des variables présentes dans la base de données affectait le prix.

## Modèle baseline

Pour construire le modèle simple, nous proposons de nous baser uniquement sur les variables numériques et catégoriques : **cat3**, **shipping**, **item_condition_id** et **is_brand_missing**.
Le modèle reposera sur le prix moyen dans le sous-groupe.

```{r}
# 10-fold cross validation
## Compte tenu de la simplicité du modèle, il est possible dans ce cas de procéder à une 10 fold-CV pour évaluer la variance de l'erreur.
list_folds = 1:10
dataset$num_fold = sample(x = list_folds, replace = TRUE, size = nrow(dataset))
```

On crée une fonction qui va évaluer la prédiction sur chaque subset des données.

```{r}
# Fonction de prédiction
predict_groupe = function(train, test){
  
  # Prix lorsqu'il n'y a pas d'exemple d'apprentissage
  ## Va au final remplacer les NA issus de la jointure future
  mean_log_price = train$log_price %>% mean()
  
  # Apprentissage sur la base de train à partir des catégories
  price_cat = train %>%
    group_by(cat3, is_brand_missing, item_condition_id, shipping) %>%
    summarise(log_price_pred = log_price %>% mean()) %>%
    ungroup()
  
  # Prédiction
  predictions = test %>%
    left_join(price_cat, by = c("item_condition_id", "cat3", "shipping", "is_brand_missing")) 
  
  # Remplace les NA par le prix moyen sur l'ensemble
  predictions$log_price_pred[is.na(predictions$log_price_pred)] = mean_log_price
  
  return(predictions)
}
```

Dès lors, il devient possible de faire les itérations pour prédire le prix.

```{r}
# Vecteur qui va conserver le score de chaque prédiction 
vect_score = c()

# On boucle sur les folds
for(f in list_folds){
  
  # Partitionnement : train / test
  train = dataset %>%
    filter(num_fold != f)
  
  test = dataset %>%
    filter(num_fold == f)
  
  # Apprentissage et prédiction
  predictions = predict_groupe(train, test)

  # Mesure de la performance
  score_rmse = rmse(predictions$log_price, predictions$log_price_pred)
  cat(sprintf("Fold %-8s Le score de prédiction est de %.3f.\n", f, score_rmse))
  
  # On rajoute le score de ce fold
  vect_score = c(vect_score, score_rmse)
  
}

# On mesure la variance de l'erreur
cat(sprintf("Le score moyen de ce prédicteur est de %.3f +/- %.3f (à 95%%).\n",
            mean(vect_score), 
            2/sqrt(length(vect_score)) * sd(vect_score)
            )
    )
```

## Modèle de random forest

Il nous faut un modèle capable de gérer des centaines de variables, avec de bons taux de prédictions, et capable de faire un "nettoyage automatique" des données. Pour cela, nous privilégions les modèles de forêts aléatoires sur les arbres de décision (moins bon en score), les régressions linéaires (plus sensibles au bruit), aux réseaux bayésiens et aux réseaux de neurones à une/deux couches.

### Création de la matrice

On ne se basera que sur les variables catégorielles, numériques et sur le nom des produit. Ici, l'effet de la description est négligée (pour des raisons principalement techniques et de temps de calcul).

Une fois la matrice des mots sera obtenue et on rajoutera les autres variables : **cat2**, **cat3**, **shipping**, **item_condition_id** et **brand_name** pour enfin prédire le prix.

```{r}
# Création du corpus de noms de produits
corpus_name = Corpus(VectorSource(dataset$name) ,list(language = "english"))
corpus_name = tm_map(corpus_name, tolower)
corpus_name = tm_map(corpus_name, removePunctuation)
corpus_name = tm_map(corpus_name, stripWhitespace)
# on conserve les stopwords : 'for', 'with' ou encore 'and' apporte de l'information sur la nature du produit

```

Une fois le corpus obtenu, on crée la matrice.

```{r}
# Suppression des mots rares de la matrice
ndocs = length(corpus_name)
min_support = 0.001
minDocFreq = ndocs * min_support 

# Matrice Documents x Terms pour les noms des produits
documentTerm_name = DocumentTermMatrix(corpus_name, control = list(bounds = list(global = c(minDocFreq,ndocs)),
                                                              weighting = "weightBin"))
mat_name = as.matrix(documentTerm_name) #mise en matrice
mat_name = data.frame(mat_name > 0) #binarisation
dim(mat_name) #le nombre de colonne indique le nombre de mots
```

On rajoute les autres variables. Ici, il faut penser à rajouter un marqueur ("var_") pour distinguer le nom de la variable des mots présents dans le nom. Par exemple, shipping peut soit correspondre à la variable binaire présente depuis le départ dans les données, soit au propre mot présent dans le nom.

```{r}
mat_name$var_cat2 = dataset$cat2
mat_name$var_cat3 = dataset$cat3
mat_name$var_brand_name = dataset$brand_name
mat_name$var_shipping = dataset$shipping
mat_name$var_item_condition_id = dataset$item_condition_id
mat_name$log_price = dataset$log_price
```

On peut enfin faire la prédiction
```{r}
# Ensemble d'apprentissage
training_rows = sample(c(TRUE, FALSE), 
                       replace = TRUE, 
                       size = nrow(mat_name), 
                       prob = c(0.8, 0.2)) #80% vs 20% en test

# Modèle de random forest avec 64 arbres
## do.trace : permet de mesurer le MSE au cours de la construction de la forêt
## la construction est séquentielle : un arbre puis un autre, puis un autre ...

begin_time = Sys.time()
model_rf = randomForest(log_price ~ . , data = mat_name, subset = training_rows, ntree = 40, do.trace = TRUE, mtry = 40)
time_elapsed = Sys.time() - begin_time
time_elapsed

model_rf
```

On peut désormais prédire et mesurer l'erreur sur la base de test : 

```{r}
# Prédictions sur les 20% restantes
predict_rf = predict(model_rf, mat_name[!training_rows, ])

# Mesure de l'erreur sur la base de test
rmse_test = rmse(y_true = mat_name[!training_rows, "log_price"], y_pred = predict_rf)
cat(sprintf("Le RMSE sur la base de test vaut %.3f, soit un MSE de %.3f.\n", 
           rmse_test, rmse_test**2))
```

Avec cat2, cat3, brand_name, shipping, item_condition_id, name (low, punt, strip), le MSE lors de l'apprentissage est de 0.292 et celui du test est de 0.287, soit un RMSE de 0.536 (modulo le random lors du split train/test).

```{r}
# On sauvegarde le modèle au cas où ...
#save(model_rf, file = "./results/model_rf_40tree_40var.RData")
```

Quelles sont les variables les plus importantes ?

```{r}
# Importance des variables
varImpPlot(model_rf, n.var = 50)
importance(model_rf) %>% as.data.frame() %>% mutate(word = rownames(.)) %>% arrange(-IncNodePurity) %>% head(30)
```

## Cohérence du modèle

Vérifions la cohérence du modèle : il faut que ,toute chose égale par ailleurs, un shipping à 1 (vendeur paie les frais d'envoi) soit plus cher que un shiping à 0. De même, toute chose égale par ailleurs, il faudrait que l'accroissement de l'état (= détérioration) se traduise par une réduction de prix de l'article. 

```{r}
# On crée de fausses données où une seule variable va changer
## On pourra mesurer l'impact de celle ci, toute chose égale par ailleurs
## On sélectionne un article au choix, ici un case pour iPhone 6
fake_dataset = mat_name[39, ]
fake_dataset = fake_dataset[rep(1, each=10),]
rownames(fake_dataset) = 1:10

# shipping
fake_dataset$var_shipping = as.integer(rownames(fake_dataset)) %% 2

# item_condition_id
fake_dataset$var_item_condition_id = (1 + (as.integer(rownames(fake_dataset)) %% 5)) %>% as.factor()

# On prédit à partir du random forest
predict_fake = predict(model_rf, fake_dataset)

```


### Cohérence par rapport à shipping
```{r}
#Lecture des résultats avec une remise en forme
fake_df = data.frame(shipping = fake_dataset$var_shipping,
                     item_condition_id = fake_dataset$var_item_condition_id,
                     predict = predict_fake)

### Cohérence par rapport à shipping et à item_condition_id
fake_df %>% arrange(shipping, item_condition_id)
```

Ces résultats montrent que bien que le random forest ait de bons scores de prédiction (en RMSE), il n'arrive pas à se défaire des biais de sélection présents dans les données. En effet, le passage de shipping de 0 à 1 réduit systématiquement le prix (!!) et la dégradation n'implique pas forcément une réduction du prix.

